{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5747fbb5",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-10T17:22:22.847676Z",
     "iopub.status.busy": "2025-06-10T17:22:22.846922Z",
     "iopub.status.idle": "2025-06-10T17:22:31.589625Z",
     "shell.execute_reply": "2025-06-10T17:22:31.588784Z"
    },
    "papermill": {
     "duration": 8.748147,
     "end_time": "2025-06-10T17:22:31.591104",
     "exception": false,
     "start_time": "2025-06-10T17:22:22.842957",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import math\n",
    "\n",
    "dataset_path = '/kaggle/input/unipd-deep-learning-2025-challenge-2/train_dataset.csv'\n",
    "\n",
    "df = pd.read_csv(dataset_path)\n",
    "feature_cols = [c for c in df.columns if c not in ('station', 'time')]\n",
    "df_sorted = df.sort_values(['station', 'time'])\n",
    "values = df_sorted[feature_cols].to_numpy()\n",
    "n_stations = df['station'].nunique()\n",
    "n_times = df['time'].nunique()\n",
    "n_features = len(feature_cols)\n",
    "dataset_tensor = values.reshape(n_stations, n_times, n_features)\n",
    "input_window = 60\n",
    "forecast_horizon = 30\n",
    "train_split = 0.9999\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "train_tensor = dataset_tensor[:, :-input_window]\n",
    "test_tensor = dataset_tensor[:, -input_window:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e92959ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T17:22:31.597642Z",
     "iopub.status.busy": "2025-06-10T17:22:31.597367Z",
     "iopub.status.idle": "2025-06-10T17:22:33.941202Z",
     "shell.execute_reply": "2025-06-10T17:22:33.940632Z"
    },
    "papermill": {
     "duration": 2.348603,
     "end_time": "2025-06-10T17:22:33.942593",
     "exception": false,
     "start_time": "2025-06-10T17:22:31.593990",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import skew\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import sklearn.preprocessing as sk \n",
    "from scipy import stats\n",
    "import sklearn.preprocessing as sk\n",
    "\n",
    "def transform_weather_data(data_tensor, forward=True, method='box-cox', standardize=True, transformers=None, skew_threshold=1.0):\n",
    "    transformed_data = data_tensor.copy()\n",
    "    n_stations, n_days, n_features = transformed_data.shape\n",
    "    if forward:\n",
    "        if transformers is not None:\n",
    "            for i in range(n_features):\n",
    "                transformer = transformers[i]\n",
    "                if transformer is None:\n",
    "                    raise ValueError(f'A provided transformer is missing for feature {i + 1}')\n",
    "                feature_data = transformed_data[:, :, i].reshape(-1, 1)\n",
    "                transformed_data[:, :, i] = transformer.transform(feature_data).reshape(n_stations, n_days)\n",
    "        else:\n",
    "            transformers = [None] * n_features\n",
    "            for i in range(n_features):\n",
    "                feature_data = transformed_data[:, :, i].reshape(-1, 1)\n",
    "                skew = stats.skew(feature_data.flatten())\n",
    "                if abs(skew) > skew_threshold:\n",
    "                    if standardize:\n",
    "                        transformer = sk.StandardScaler()\n",
    "                    else:\n",
    "                        transformer = sk.FunctionTransformer()\n",
    "                else:\n",
    "                    # If skew is below threshold, skip power transforms and just standardize or passthrough\n",
    "                    if standardize:\n",
    "                        transformer = sk.StandardScaler()\n",
    "                    else:\n",
    "                        transformer = sk.FunctionTransformer()\n",
    "\n",
    "                transformed_data[:, :, i] = transformer.fit_transform(feature_data).reshape(n_stations, n_days)\n",
    "                transformers[i] = transformer\n",
    "\n",
    "        return transformed_data, transformers\n",
    "    else:\n",
    "        if transformers is None:\n",
    "            raise ValueError(\"For backpass transformers must be provided\")\n",
    "        for i in range(n_features):\n",
    "            feature_data = transformed_data[:, :, i].reshape(-1, 1)\n",
    "            transformer = transformers[i]\n",
    "            if transformer is None:\n",
    "                raise ValueError(f\"Transformer missing for feature {i + 1}\")\n",
    "            transformed_data[:, :, i] = transformer.inverse_transform(feature_data).reshape(n_stations, n_days)\n",
    "\n",
    "        return transformed_data, transformers\n",
    "\n",
    "transformed_train_tensor, transformers = transform_weather_data(train_tensor, forward=True, method='none', standardize=True, skew_threshold=0)\n",
    "transformed_test_tensor, _ = transform_weather_data(test_tensor, forward=True, transformers=transformers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21a6bf3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T17:22:33.948689Z",
     "iopub.status.busy": "2025-06-10T17:22:33.948345Z",
     "iopub.status.idle": "2025-06-10T17:22:33.955901Z",
     "shell.execute_reply": "2025-06-10T17:22:33.955373Z"
    },
    "papermill": {
     "duration": 0.01187,
     "end_time": "2025-06-10T17:22:33.956898",
     "exception": false,
     "start_time": "2025-06-10T17:22:33.945028",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class DatasetW(Dataset):\n",
    "    def __init__(self, data, train=False, input_window=30, forecast_horizon=30):\n",
    "        self.data = data\n",
    "        self.input_window = input_window\n",
    "        self.forecast_horizon = forecast_horizon\n",
    "        self.samples = []\n",
    "\n",
    "        num_stations, num_days, _ = data.shape\n",
    "\n",
    "        for station in range(num_stations):\n",
    "            if train:\n",
    "                windows = range(num_days - input_window - forecast_horizon + 1)\n",
    "            else:\n",
    "                windows = range(num_days - input_window + 1)\n",
    "            for start in windows:\n",
    "                station_feature = torch.full((input_window, 1), station, dtype=torch.float32)\n",
    "                day_feature = torch.arange(start, start+input_window, dtype=torch.float32).reshape((input_window, 1))\n",
    "                weather_features = torch.tensor(data[station, start:start + input_window], dtype=torch.float32)\n",
    "                input_seq = torch.cat([station_feature, day_feature, weather_features], dim=1)\n",
    "\n",
    "                if train:\n",
    "                    station_feature_target = torch.full((forecast_horizon, 1), station, dtype=torch.float32)\n",
    "                    day_feature_target = torch.arange(start+input_window, start+input_window+forecast_horizon, dtype=torch.float32).reshape((forecast_horizon, 1))\n",
    "                    weather_features_target = torch.tensor(data[station, start + input_window:start + input_window + forecast_horizon], dtype=torch.float32)\n",
    "                    target_seq = torch.cat([station_feature_target, day_feature_target, weather_features_target], dim=1)\n",
    "                \n",
    "                    self.samples.append((input_seq, target_seq))\n",
    "                else:\n",
    "                    self.samples.append(input_seq)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.samples[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3c24257",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T17:22:33.961793Z",
     "iopub.status.busy": "2025-06-10T17:22:33.961584Z",
     "iopub.status.idle": "2025-06-10T17:22:56.975986Z",
     "shell.execute_reply": "2025-06-10T17:22:56.975207Z"
    },
    "papermill": {
     "duration": 23.018198,
     "end_time": "2025-06-10T17:22:56.977248",
     "exception": false,
     "start_time": "2025-06-10T17:22:33.959050",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_loader) = 225\n",
      "len(val_loader) = 1\n",
      "len(test_loader) = 422\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "batch_size = 1024\n",
    "\n",
    "train_dataset, val_dataset = random_split(\n",
    "  DatasetW(transformed_train_tensor, train=True, input_window=input_window, forecast_horizon=forecast_horizon),\n",
    "  lengths=[train_split, 1 - train_split]\n",
    ")\n",
    "test_dataset = DatasetW(transformed_test_tensor, train=False, input_window=input_window)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "print(f'len(train_loader) = {len(train_loader)}')\n",
    "print(f'len(val_loader) = {len(val_loader)}')\n",
    "print(f'len(test_loader) = {len(test_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f96828a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T17:22:56.982718Z",
     "iopub.status.busy": "2025-06-10T17:22:56.982494Z",
     "iopub.status.idle": "2025-06-10T17:22:56.986579Z",
     "shell.execute_reply": "2025-06-10T17:22:56.986049Z"
    },
    "papermill": {
     "duration": 0.00797,
     "end_time": "2025-06-10T17:22:56.987594",
     "exception": false,
     "start_time": "2025-06-10T17:22:56.979624",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mase_loss(y_pred, y_true, y_history):\n",
    "    mae_model = torch.mean(torch.abs(y_true - y_pred))\n",
    "    last_observed = y_history[:, -1:, :]  # (batch, 1, input_dim)\n",
    "    naive_forecast = last_observed.repeat(1, y_true.shape[1], 1)  # (not repeat batch, forecast_horizon, not repeat input_dim)\n",
    "    mae_naive = torch.mean(torch.abs(y_true - naive_forecast))\n",
    "    return mae_model / (mae_naive + 1e-8)  # avoid division by zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa9195a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T17:22:56.992589Z",
     "iopub.status.busy": "2025-06-10T17:22:56.992384Z",
     "iopub.status.idle": "2025-06-10T17:22:57.005422Z",
     "shell.execute_reply": "2025-06-10T17:22:57.004745Z"
    },
    "papermill": {
     "duration": 0.016834,
     "end_time": "2025-06-10T17:22:57.006481",
     "exception": false,
     "start_time": "2025-06-10T17:22:56.989647",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self,weather_features,num_stations,station_embed_dim,hidden_size,num_layers,dropout,forecast_horizon,):\n",
    "        super().__init__()\n",
    "\n",
    "        self.weather_features = weather_features\n",
    "        self.station_embed_dim = station_embed_dim\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout_p = dropout\n",
    "        self.forecast_horizon = forecast_horizon\n",
    "        self.station_embedding = nn.Embedding(num_stations, station_embed_dim)\n",
    "        self.input_size = station_embed_dim + 2 + weather_features\n",
    "        self.lstm_cells = nn.ModuleList()\n",
    "        for layer_idx in range(num_layers):\n",
    "            input_dim = self.input_size if layer_idx == 0 else hidden_size\n",
    "            cell = nn.LSTMCell(input_size=input_dim, hidden_size=hidden_size)\n",
    "            self.lstm_cells.append(cell)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.output_projection = nn.Linear(hidden_size, weather_features)\n",
    "\n",
    "    def _encode(self, station_ids: torch.LongTensor, day_values: torch.Tensor, weather_feats: torch.Tensor):\n",
    "        station_embeds = self.station_embedding(station_ids)\n",
    "        day_vals = day_values.float()\n",
    "        day_rad = 2 * math.pi * day_vals / 365.25\n",
    "        day_sin = torch.sin(day_rad).unsqueeze(1)\n",
    "        day_cos = torch.cos(day_rad).unsqueeze(1)\n",
    "        cyclical_day = torch.cat([day_sin, day_cos], dim=1)\n",
    "        return torch.cat([station_embeds, cyclical_day, weather_feats], dim=1)\n",
    "\n",
    "    def forward(self, src: torch.Tensor):\n",
    "        batch_size, seq_len, input_dim = src.shape\n",
    "        device = src.device\n",
    "        station_ids = src[:, 0, 0].long().to(device)\n",
    "        day_seq = src[:, :, 1].to(device)\n",
    "        weather_seq = src[:, :, 2:].to(device)\n",
    "        h_states = [\n",
    "            torch.zeros(batch_size, self.hidden_size, device=device)\n",
    "            for _ in range(self.num_layers)\n",
    "        ]\n",
    "        c_states = [\n",
    "            torch.zeros(batch_size, self.hidden_size, device=device)\n",
    "            for _ in range(self.num_layers)\n",
    "        ]\n",
    "\n",
    "        for t in range(seq_len):\n",
    "            day_t = day_seq[:, t]\n",
    "            weather_t = weather_seq[:, t, :]\n",
    "            step_input = self._encode(station_ids, day_t, weather_t)\n",
    "            for layer_idx, cell in enumerate(self.lstm_cells):\n",
    "                h_prev, c_prev = h_states[layer_idx], c_states[layer_idx]\n",
    "                if layer_idx == 0:\n",
    "                    inp = step_input\n",
    "                else:\n",
    "                    inp = self.dropout(h_states[layer_idx - 1])\n",
    "                h_new, c_new = cell(inp, (h_prev, c_prev))\n",
    "                h_states[layer_idx], c_states[layer_idx] = h_new, c_new\n",
    "\n",
    "        predictions = []\n",
    "        last_day = day_seq[:, -1]\n",
    "        last_weather = weather_seq[:, -1, :]\n",
    "\n",
    "        for step in range(self.forecast_horizon):\n",
    "            next_day = last_day + 1.0 + step\n",
    "            step_inp = self._encode(station_ids, next_day, last_weather)\n",
    "            for layer_idx, cell in enumerate(self.lstm_cells):\n",
    "                h_prev, c_prev = h_states[layer_idx], c_states[layer_idx]\n",
    "                if layer_idx == 0:\n",
    "                    inp = step_inp\n",
    "                else:\n",
    "                    inp = self.dropout(h_states[layer_idx - 1])\n",
    "                h_new, c_new = cell(inp, (h_prev, c_prev))\n",
    "                h_states[layer_idx], c_states[layer_idx] = h_new, c_new\n",
    "            top_h = h_states[-1]\n",
    "            pred_weather = self.output_projection(self.dropout(top_h)).unsqueeze(1)\n",
    "            predictions.append(pred_weather)\n",
    "            last_weather = pred_weather.squeeze(1)\n",
    "\n",
    "        return torch.cat(predictions, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76cfa6e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T17:22:57.011363Z",
     "iopub.status.busy": "2025-06-10T17:22:57.011132Z",
     "iopub.status.idle": "2025-06-10T17:22:57.022102Z",
     "shell.execute_reply": "2025-06-10T17:22:57.021472Z"
    },
    "papermill": {
     "duration": 0.014599,
     "end_time": "2025-06-10T17:22:57.023071",
     "exception": false,
     "start_time": "2025-06-10T17:22:57.008472",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch.nn.utils import clip_grad_norm_ as clip_grad_norm\n",
    "\n",
    "def lr_lambda(current_step: int, warmup_steps: int, total_steps: int):\n",
    "    if current_step < warmup_steps:\n",
    "        return float(current_step) / float(max(1, warmup_steps))\n",
    "    progress = float(current_step - warmup_steps) / float(max(1, total_steps - warmup_steps))\n",
    "    return 0.5 * (1.0 + math.cos(math.pi * progress))\n",
    "\n",
    "def train_model(model: nn.Module,train_loader: torch.utils.data.DataLoader,val_loader: torch.utils.data.DataLoader,model_type: str = 'unk',num_epochs: int = 100,lr: float = 1e-4,warmup_steps: int = 1000,weight_decay: float = 1e-4,patience: int = 5,grad_clip: float = 1.3,device: str = 'cuda',save_path: str = 'models/'):\n",
    "\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    total_steps = len(train_loader) * num_epochs\n",
    "    scheduler = LambdaLR(\n",
    "        optimizer=optimizer,\n",
    "        lr_lambda=lambda step: lr_lambda(step, warmup_steps, total_steps)\n",
    "    )\n",
    "\n",
    "    criterion = nn.L1Loss()\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        model.train()\n",
    "        total_train_loss = 0.0\n",
    "        total_train_mase = 0.0\n",
    "\n",
    "        for batch_idx, (src, tgt) in enumerate(train_loader, start=1):\n",
    "            src = src.to(device)\n",
    "            tgt = tgt.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(src)\n",
    "\n",
    "            loss = criterion(output, tgt[:, :, 2:])\n",
    "            loss.backward()\n",
    "\n",
    "            clip_grad_norm(model.parameters(), max_norm=grad_clip)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "            total_train_mase += mase_loss(output, tgt[:, :, 2:], src[:, :, 2:]).item()\n",
    "\n",
    "            if batch_idx % 300 == 0:\n",
    "                print(\n",
    "                    f\"[Epoch {epoch:02d} | Batch {batch_idx:04d}] \"\n",
    "                    f\"MAE: {loss.item():.4f} | MASE: {total_train_mase / batch_idx:.4f}\"\n",
    "                )\n",
    "\n",
    "        mean_train_loss = total_train_loss / len(train_loader)\n",
    "        mean_train_mase = total_train_mase / len(train_loader)\n",
    "\n",
    "        model.eval()\n",
    "        total_val_loss = 0.0\n",
    "        total_val_mase = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for src, tgt in val_loader:\n",
    "                src = src.to(device)\n",
    "                tgt = tgt.to(device)\n",
    "                pred = model(src)\n",
    "\n",
    "                val_loss = criterion(pred, tgt[:, :, 2:]).item()\n",
    "                val_mase = mase_loss(pred, tgt[:, :, 2:], src[:, :, 2:]).item()\n",
    "\n",
    "                total_val_loss += val_loss\n",
    "                total_val_mase += val_mase\n",
    "\n",
    "        mean_val_loss = total_val_loss / len(val_loader)\n",
    "        mean_val_mase = total_val_mase / len(val_loader)\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {epoch:02d}/{num_epochs} | \"\n",
    "            f\"Train MAE: {mean_train_loss:.4f} | Train MASE: {mean_train_mase:.4f} | \"\n",
    "            f\"Val   MAE: {mean_val_loss:.4f} | Val   MASE: {mean_val_mase:.4f}\"\n",
    "        )\n",
    "\n",
    "        if mean_train_loss < best_val_loss - 0.004:\n",
    "            best_val_loss = mean_train_loss\n",
    "            epochs_no_improve = 0\n",
    "            checkpoint_path = os.path.join(save_path, f\"epoch_{epoch:02d}.pt\")\n",
    "            torch.save(model.state_dict(), checkpoint_path)\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= patience:\n",
    "                print(f\"\\nEarly stopping at epoch {epoch} (no improvement for {patience} epochs).\")\n",
    "                break\n",
    "        print(epochs_no_improve)\n",
    "    print(f\"\\nBest validation MAE = {best_val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bd83239",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T17:22:57.028090Z",
     "iopub.status.busy": "2025-06-10T17:22:57.027601Z",
     "iopub.status.idle": "2025-06-10T17:43:37.077706Z",
     "shell.execute_reply": "2025-06-10T17:43:37.076900Z"
    },
    "papermill": {
     "duration": 1240.057828,
     "end_time": "2025-06-10T17:43:37.083012",
     "exception": false,
     "start_time": "2025-06-10T17:22:57.025184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device=cuda\n",
      "Epoch 01/120 | Train MAE: 0.5840 | Train MASE: 0.9629 | Val   MAE: 0.4770 | Val   MASE: 0.9489\n",
      "0\n",
      "Epoch 02/120 | Train MAE: 0.5194 | Train MASE: 0.8564 | Val   MAE: 0.3741 | Val   MASE: 0.7441\n",
      "0\n",
      "Epoch 03/120 | Train MAE: 0.4768 | Train MASE: 0.7860 | Val   MAE: 0.3514 | Val   MASE: 0.6990\n",
      "0\n",
      "Epoch 04/120 | Train MAE: 0.4557 | Train MASE: 0.7512 | Val   MAE: 0.3369 | Val   MASE: 0.6701\n",
      "0\n",
      "Epoch 05/120 | Train MAE: 0.4409 | Train MASE: 0.7269 | Val   MAE: 0.3313 | Val   MASE: 0.6590\n",
      "0\n",
      "Epoch 06/120 | Train MAE: 0.4327 | Train MASE: 0.7135 | Val   MAE: 0.3286 | Val   MASE: 0.6537\n",
      "0\n",
      "Epoch 07/120 | Train MAE: 0.4274 | Train MASE: 0.7046 | Val   MAE: 0.3252 | Val   MASE: 0.6469\n",
      "0\n",
      "Epoch 08/120 | Train MAE: 0.4235 | Train MASE: 0.6983 | Val   MAE: 0.3212 | Val   MASE: 0.6389\n",
      "1\n",
      "Epoch 09/120 | Train MAE: 0.4206 | Train MASE: 0.6935 | Val   MAE: 0.3201 | Val   MASE: 0.6367\n",
      "0\n",
      "Epoch 10/120 | Train MAE: 0.4184 | Train MASE: 0.6897 | Val   MAE: 0.3190 | Val   MASE: 0.6346\n",
      "1\n",
      "Epoch 11/120 | Train MAE: 0.4164 | Train MASE: 0.6866 | Val   MAE: 0.3176 | Val   MASE: 0.6317\n",
      "0\n",
      "Epoch 12/120 | Train MAE: 0.4147 | Train MASE: 0.6838 | Val   MAE: 0.3162 | Val   MASE: 0.6289\n",
      "1\n",
      "Epoch 13/120 | Train MAE: 0.4133 | Train MASE: 0.6814 | Val   MAE: 0.3160 | Val   MASE: 0.6285\n",
      "2\n",
      "Epoch 14/120 | Train MAE: 0.4120 | Train MASE: 0.6794 | Val   MAE: 0.3147 | Val   MASE: 0.6260\n",
      "0\n",
      "Epoch 15/120 | Train MAE: 0.4109 | Train MASE: 0.6775 | Val   MAE: 0.3142 | Val   MASE: 0.6250\n",
      "1\n",
      "Epoch 16/120 | Train MAE: 0.4098 | Train MASE: 0.6757 | Val   MAE: 0.3144 | Val   MASE: 0.6254\n",
      "2\n",
      "Epoch 17/120 | Train MAE: 0.4088 | Train MASE: 0.6741 | Val   MAE: 0.3130 | Val   MASE: 0.6227\n",
      "3\n",
      "Epoch 18/120 | Train MAE: 0.4079 | Train MASE: 0.6725 | Val   MAE: 0.3128 | Val   MASE: 0.6222\n",
      "0\n",
      "Epoch 19/120 | Train MAE: 0.4071 | Train MASE: 0.6711 | Val   MAE: 0.3121 | Val   MASE: 0.6208\n",
      "1\n",
      "Epoch 20/120 | Train MAE: 0.4063 | Train MASE: 0.6698 | Val   MAE: 0.3120 | Val   MASE: 0.6206\n",
      "2\n",
      "Epoch 21/120 | Train MAE: 0.4054 | Train MASE: 0.6685 | Val   MAE: 0.3110 | Val   MASE: 0.6186\n",
      "3\n",
      "Epoch 22/120 | Train MAE: 0.4047 | Train MASE: 0.6672 | Val   MAE: 0.3113 | Val   MASE: 0.6193\n",
      "4\n",
      "Epoch 23/120 | Train MAE: 0.4040 | Train MASE: 0.6661 | Val   MAE: 0.3111 | Val   MASE: 0.6189\n",
      "5\n",
      "Epoch 24/120 | Train MAE: 0.4033 | Train MASE: 0.6649 | Val   MAE: 0.3114 | Val   MASE: 0.6195\n",
      "0\n",
      "Epoch 25/120 | Train MAE: 0.4027 | Train MASE: 0.6640 | Val   MAE: 0.3105 | Val   MASE: 0.6176\n",
      "1\n",
      "Epoch 26/120 | Train MAE: 0.4021 | Train MASE: 0.6630 | Val   MAE: 0.3103 | Val   MASE: 0.6172\n",
      "2\n",
      "Epoch 27/120 | Train MAE: 0.4015 | Train MASE: 0.6620 | Val   MAE: 0.3099 | Val   MASE: 0.6164\n",
      "3\n",
      "Epoch 28/120 | Train MAE: 0.4010 | Train MASE: 0.6612 | Val   MAE: 0.3099 | Val   MASE: 0.6163\n",
      "4\n",
      "Epoch 29/120 | Train MAE: 0.4005 | Train MASE: 0.6603 | Val   MAE: 0.3099 | Val   MASE: 0.6163\n",
      "5\n",
      "Epoch 30/120 | Train MAE: 0.3999 | Train MASE: 0.6594 | Val   MAE: 0.3093 | Val   MASE: 0.6153\n",
      "6\n",
      "Epoch 31/120 | Train MAE: 0.3996 | Train MASE: 0.6588 | Val   MAE: 0.3089 | Val   MASE: 0.6145\n",
      "7\n",
      "Epoch 32/120 | Train MAE: 0.3991 | Train MASE: 0.6580 | Val   MAE: 0.3089 | Val   MASE: 0.6144\n",
      "0\n",
      "Epoch 33/120 | Train MAE: 0.3986 | Train MASE: 0.6572 | Val   MAE: 0.3087 | Val   MASE: 0.6139\n",
      "1\n",
      "Epoch 34/120 | Train MAE: 0.3981 | Train MASE: 0.6564 | Val   MAE: 0.3091 | Val   MASE: 0.6148\n",
      "2\n",
      "Epoch 35/120 | Train MAE: 0.3977 | Train MASE: 0.6557 | Val   MAE: 0.3081 | Val   MASE: 0.6129\n",
      "3\n",
      "Epoch 36/120 | Train MAE: 0.3973 | Train MASE: 0.6551 | Val   MAE: 0.3084 | Val   MASE: 0.6134\n",
      "4\n",
      "Epoch 37/120 | Train MAE: 0.3970 | Train MASE: 0.6545 | Val   MAE: 0.3079 | Val   MASE: 0.6124\n",
      "5\n",
      "Epoch 38/120 | Train MAE: 0.3965 | Train MASE: 0.6537 | Val   MAE: 0.3072 | Val   MASE: 0.6111\n",
      "6\n",
      "Epoch 39/120 | Train MAE: 0.3962 | Train MASE: 0.6532 | Val   MAE: 0.3077 | Val   MASE: 0.6120\n",
      "7\n",
      "Epoch 40/120 | Train MAE: 0.3958 | Train MASE: 0.6525 | Val   MAE: 0.3071 | Val   MASE: 0.6108\n",
      "8\n",
      "Epoch 41/120 | Train MAE: 0.3954 | Train MASE: 0.6519 | Val   MAE: 0.3066 | Val   MASE: 0.6099\n",
      "9\n",
      "Epoch 42/120 | Train MAE: 0.3950 | Train MASE: 0.6513 | Val   MAE: 0.3069 | Val   MASE: 0.6104\n",
      "0\n",
      "Epoch 43/120 | Train MAE: 0.3948 | Train MASE: 0.6508 | Val   MAE: 0.3068 | Val   MASE: 0.6102\n",
      "1\n",
      "Epoch 44/120 | Train MAE: 0.3944 | Train MASE: 0.6503 | Val   MAE: 0.3066 | Val   MASE: 0.6099\n",
      "2\n",
      "Epoch 45/120 | Train MAE: 0.3941 | Train MASE: 0.6498 | Val   MAE: 0.3063 | Val   MASE: 0.6093\n",
      "3\n",
      "Epoch 46/120 | Train MAE: 0.3938 | Train MASE: 0.6492 | Val   MAE: 0.3066 | Val   MASE: 0.6098\n",
      "4\n",
      "Epoch 47/120 | Train MAE: 0.3935 | Train MASE: 0.6488 | Val   MAE: 0.3061 | Val   MASE: 0.6088\n",
      "5\n",
      "Epoch 48/120 | Train MAE: 0.3932 | Train MASE: 0.6483 | Val   MAE: 0.3056 | Val   MASE: 0.6078\n",
      "6\n",
      "Epoch 49/120 | Train MAE: 0.3930 | Train MASE: 0.6479 | Val   MAE: 0.3064 | Val   MASE: 0.6094\n",
      "7\n",
      "Epoch 50/120 | Train MAE: 0.3927 | Train MASE: 0.6475 | Val   MAE: 0.3061 | Val   MASE: 0.6088\n",
      "8\n",
      "Epoch 51/120 | Train MAE: 0.3925 | Train MASE: 0.6470 | Val   MAE: 0.3056 | Val   MASE: 0.6079\n",
      "9\n",
      "Epoch 52/120 | Train MAE: 0.3922 | Train MASE: 0.6466 | Val   MAE: 0.3049 | Val   MASE: 0.6065\n",
      "\n",
      "Early stopping at epoch 52 (no improvement for 10 epochs).\n",
      "\n",
      "Best validation MAE = 0.3950\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'device={device}')\n",
    "model = LSTM(\n",
    "    weather_features=76, \n",
    "    num_stations=422,\n",
    "    station_embed_dim=12,      \n",
    "    hidden_size=48,           \n",
    "    num_layers=2,\n",
    "    dropout=0.18,\n",
    "    forecast_horizon=forecast_horizon\n",
    ")\n",
    "train_model(\n",
    "    model,\n",
    "\ttrain_loader, val_loader,\n",
    "    num_epochs=120, lr=1e-4, weight_decay=5e-2, patience=10, warmup_steps=500,\n",
    "    device=device,\n",
    "    save_path='models/'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13e4a929",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T17:43:37.093420Z",
     "iopub.status.busy": "2025-06-10T17:43:37.092600Z",
     "iopub.status.idle": "2025-06-10T17:43:56.967654Z",
     "shell.execute_reply": "2025-06-10T17:43:56.966849Z"
    },
    "papermill": {
     "duration": 19.881325,
     "end_time": "2025-06-10T17:43:56.969110",
     "exception": false,
     "start_time": "2025-06-10T17:43:37.087785",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/epoch_42.pt\n",
      "      station time      var1       var2       var3       var4       var5  \\\n",
      "0           0  694  0.056131  32.286209  27.013058  22.337292  34.203274   \n",
      "1           0  695  0.035928  32.836243  27.390656  22.546234  31.375746   \n",
      "2           0  696  0.023281  33.286217  27.721127  22.763315  29.390656   \n",
      "3           0  697  0.017860  33.656418  28.002705  22.971306  28.194546   \n",
      "4           0  698  0.016914  33.947033  28.222969  23.146307  27.561415   \n",
      "...       ...  ...       ...        ...        ...        ...        ...   \n",
      "12655     421  719  0.098710  18.771652  13.812306   9.137703  30.071703   \n",
      "12656     421  720  0.098034  18.765875  13.801530   9.117914  29.952831   \n",
      "12657     421  721  0.097300  18.761576  13.791638   9.098948  29.827784   \n",
      "12658     421  722  0.096521  18.758709  13.782686   9.080891  29.698051   \n",
      "12659     421  723  0.095708  18.757233  13.774724   9.063821  29.564892   \n",
      "\n",
      "            var6      var7      var8  ...     var67     var68     var69  \\\n",
      "0      20.479431  2.162958  1.149164  ...  3.904593  1.998370  0.436227   \n",
      "1      18.209570  1.793000  0.931943  ...  3.555117  1.805846  0.391382   \n",
      "2      16.717554  1.605871  0.815175  ...  3.364844  1.702501  0.376757   \n",
      "3      15.868594  1.540015  0.767150  ...  3.276998  1.660070  0.380330   \n",
      "4      15.465140  1.547971  0.760553  ...  3.248227  1.652633  0.392289   \n",
      "...          ...       ...       ...  ...       ...       ...       ...   \n",
      "12655  13.860711  0.412910  0.105874  ...  1.625758  0.647989  0.085139   \n",
      "12656  13.783561  0.406062  0.103035  ...  1.609713  0.639677  0.082988   \n",
      "12657  13.702682  0.399497  0.100340  ...  1.593886  0.631561  0.080954   \n",
      "12658  13.619072  0.393225  0.097789  ...  1.578343  0.623663  0.079031   \n",
      "12659  13.533563  0.387249  0.095379  ...  1.563134  0.615998  0.077215   \n",
      "\n",
      "          var70     var71     var72     var73     var74     var75     var76  \n",
      "0      8.275966 -0.013679  1.426923  4.076685  0.711508 -0.012104  0.000004  \n",
      "1      7.675914 -0.013523  1.330244  3.802364  0.641589 -0.012639  0.000004  \n",
      "2      7.367681 -0.012416  1.295433  3.686713  0.607074 -0.012796  0.000004  \n",
      "3      7.233916 -0.009929  1.293464  3.661993  0.599185 -0.012150  0.000004  \n",
      "4      7.192058 -0.007003  1.306123  3.680865  0.606588 -0.011140  0.000004  \n",
      "...         ...       ...       ...       ...       ...       ...       ...  \n",
      "12655  5.017709  0.003885  0.927044  2.537159  0.508602  0.000643 -0.000003  \n",
      "12656  4.982528  0.003720  0.920613  2.519250  0.503897  0.000558 -0.000003  \n",
      "12657  4.947322  0.003570  0.914252  2.501432  0.499192  0.000480 -0.000003  \n",
      "12658  4.912299  0.003433  0.907987  2.483788  0.494514  0.000408 -0.000003  \n",
      "12659  4.877631  0.003308  0.901837  2.466384  0.489882  0.000342 -0.000003  \n",
      "\n",
      "[12660 rows x 78 columns]\n",
      "           id      var1       var2       var3       var4       var5  \\\n",
      "0         0_0  0.056131  32.286209  27.013058  22.337292  34.203274   \n",
      "1         0_1  0.035928  32.836243  27.390656  22.546234  31.375746   \n",
      "2         0_2  0.023281  33.286217  27.721127  22.763315  29.390656   \n",
      "3         0_3  0.017860  33.656418  28.002705  22.971306  28.194546   \n",
      "4         0_4  0.016914  33.947033  28.222969  23.146307  27.561415   \n",
      "...       ...       ...        ...        ...        ...        ...   \n",
      "12655  421_25  0.098710  18.771652  13.812306   9.137703  30.071703   \n",
      "12656  421_26  0.098034  18.765875  13.801530   9.117914  29.952831   \n",
      "12657  421_27  0.097300  18.761576  13.791638   9.098948  29.827784   \n",
      "12658  421_28  0.096521  18.758709  13.782686   9.080891  29.698051   \n",
      "12659  421_29  0.095708  18.757233  13.774724   9.063821  29.564892   \n",
      "\n",
      "            var6      var7      var8      var9  ...     var67     var68  \\\n",
      "0      20.479431  2.162958  1.149164  0.285905  ...  3.904593  1.998370   \n",
      "1      18.209570  1.793000  0.931943  0.210927  ...  3.555117  1.805846   \n",
      "2      16.717554  1.605871  0.815175  0.174728  ...  3.364844  1.702501   \n",
      "3      15.868594  1.540015  0.767150  0.164791  ...  3.276998  1.660070   \n",
      "4      15.465140  1.547971  0.760553  0.169662  ...  3.248227  1.652633   \n",
      "...          ...       ...       ...       ...  ...       ...       ...   \n",
      "12655  13.860711  0.412910  0.105874  0.015738  ...  1.625758  0.647989   \n",
      "12656  13.783561  0.406062  0.103035  0.014753  ...  1.609713  0.639677   \n",
      "12657  13.702682  0.399497  0.100340  0.013847  ...  1.593886  0.631561   \n",
      "12658  13.619072  0.393225  0.097789  0.013016  ...  1.578343  0.623663   \n",
      "12659  13.533563  0.387249  0.095379  0.012254  ...  1.563134  0.615998   \n",
      "\n",
      "          var69     var70     var71     var72     var73     var74     var75  \\\n",
      "0      0.436227  8.275966 -0.013679  1.426923  4.076685  0.711508 -0.012104   \n",
      "1      0.391382  7.675914 -0.013523  1.330244  3.802364  0.641589 -0.012639   \n",
      "2      0.376757  7.367681 -0.012416  1.295433  3.686713  0.607074 -0.012796   \n",
      "3      0.380330  7.233916 -0.009929  1.293464  3.661993  0.599185 -0.012150   \n",
      "4      0.392289  7.192058 -0.007003  1.306123  3.680865  0.606588 -0.011140   \n",
      "...         ...       ...       ...       ...       ...       ...       ...   \n",
      "12655  0.085139  5.017709  0.003885  0.927044  2.537159  0.508602  0.000643   \n",
      "12656  0.082988  4.982528  0.003720  0.920613  2.519250  0.503897  0.000558   \n",
      "12657  0.080954  4.947322  0.003570  0.914252  2.501432  0.499192  0.000480   \n",
      "12658  0.079031  4.912299  0.003433  0.907987  2.483788  0.494514  0.000408   \n",
      "12659  0.077215  4.877631  0.003308  0.901837  2.466384  0.489882  0.000342   \n",
      "\n",
      "          var76  \n",
      "0      0.000004  \n",
      "1      0.000004  \n",
      "2      0.000004  \n",
      "3      0.000004  \n",
      "4      0.000004  \n",
      "...         ...  \n",
      "12655 -0.000003  \n",
      "12656 -0.000003  \n",
      "12657 -0.000003  \n",
      "12658 -0.000003  \n",
      "12659 -0.000003  \n",
      "\n",
      "[12660 rows x 77 columns]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "models_path = 'models'\n",
    "model_name = sorted(glob.glob(os.path.join(models_path, '*.pt')), reverse = True)[0]\n",
    "print(model_name)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if model_name is not None:\n",
    "  model.load_state_dict(torch.load(model_name, weights_only=True))\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "results_df = pd.DataFrame(columns=df.columns, index=None)\n",
    "for station, station_seq in enumerate(test_loader):\n",
    "  pred = model(station_seq.to(device))\n",
    "  pred, _ = transform_weather_data(pred.detach().cpu().numpy(), forward=False, transformers=transformers)\n",
    "  pred = pred[0]\n",
    "  station_df = pd.DataFrame(pred, columns=results_df.columns[2:])\n",
    "  station_df.insert(0, 'station', [station]*pred.shape[0])\n",
    "  station_df.insert(1, 'time', range(df['time'].max(), df['time'].max() + pred.shape[0]))\n",
    "  results_df = pd.concat([results_df, station_df], ignore_index=True)\n",
    "\n",
    "print(results_df)\n",
    "results = results_df.copy()\n",
    "results['time'] -= results['time'].min()\n",
    "results.insert(0, 'id', [ f'{station}_{time}' for station, time in zip(results['station'], results['time'])])\n",
    "results.drop(['station', 'time'], axis=1, inplace=True)\n",
    "print(results)\n",
    "\n",
    "results.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 12429606,
     "sourceId": 102815,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1301.818765,
   "end_time": "2025-06-10T17:44:00.488919",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-10T17:22:18.670154",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
